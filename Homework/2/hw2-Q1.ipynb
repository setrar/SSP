{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2cf2736-0a7c-449c-975a-3c894fd5487b",
   "metadata": {},
   "source": [
    "# ${\\color{Blue} \\text{ Bayesian Parameter Estimation}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea806e-6b6b-4915-a035-4d59ad3bda89",
   "metadata": {},
   "source": [
    "### ${\\color{Purple}1.} {\\color{Blue} \\text{On the Beneficial Bias of MMSE Estimation}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40d8c7-dbcb-42fa-8df5-9eb54bae99de",
   "metadata": {},
   "source": [
    "${\\color{Blue} \\text {Consider the Bayesian linear model } Y = H \\theta+V \\text{ with } \\theta \\sim N(0,C_{\\theta\\theta}) \\text{ and } V \\sim N(0,C_{VV} ) \\text{ independent }} $\n",
    "${\\color{Blue} \\text{ (we consider here } m_{\\theta} = 0 \\text{ for simplicity) } .} \\qquad \\qquad$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618c649-90dc-44b4-8e6a-a34d39768977",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(a)}$ ${\\color{Blue} \\text{ The LMMSE estimator is} \\hat{\\theta}_{LMMSE} = C_{\\theta Y} C_{YY}^{−1}Y =(C_{\\theta\\theta}^{−1}+ H^T C_{VV}^{−1} H)^{−1} H^T C_{VV}^{−1} Y }$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474431d-6b8f-49ae-873a-c1408da605aa",
   "metadata": {},
   "source": [
    "${\\color{Blue}  \\text{ What are the unconstrained (non-linear) MMSE and the MAP estimators? }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dee58f-6058-4dcf-bcf5-012affc462ed",
   "metadata": {},
   "source": [
    "The Linear Minimum Mean Squared Error (LMMSE) estimator is given by:\n",
    "\n",
    "$ \\hat{\\theta}_{\\text{LMMSE}} = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} Y $\n",
    "\n",
    "Let's revisit the Unconstrained Minimum Mean Squared Error (MMSE) and the Maximum A Posteriori (MAP) estimators.\n",
    "\n",
    "1. **Unconstrained (Non-linear) MMSE Estimator:**\n",
    "\n",
    "The unconstrained MMSE estimator is obtained by minimizing the mean squared error without any constraints on the parameter. In the Bayesian framework, the unconstrained MMSE estimator is also known as the posterior mean, and it is given by the mean of the posterior distribution. In the case where $ \\theta $ follows a normal distribution, the posterior mean is equal to the posterior distribution's mean:\n",
    "\n",
    "$ \\hat{\\theta}_{\\text{MMSE}} = (C_{\\theta \\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} Y $\n",
    "\n",
    "This is the same expression as the LMMSE estimator in this case.\n",
    "\n",
    "2. **Maximum A Posteriori (MAP) Estimator:**\n",
    "\n",
    "The MAP estimator seeks the most probable value of the parameter given the observed data and the prior information. It is obtained by maximizing the posterior distribution:\n",
    "\n",
    "$ \\hat{\\theta}_{\\text{MAP}} = \\arg \\max_{\\theta} P(\\theta | Y) $\n",
    "\n",
    "In the case of a Gaussian prior, this is equivalent to minimizing the negative log posterior, and the MAP estimator is obtained as:\n",
    "\n",
    "$ \\hat{\\theta}_{\\text{MAP}} = \\arg \\min_{\\theta} \\left[ \\frac{1}{2} (Y - H \\theta)^T C_{VV}^{-1} (Y - H \\theta) + \\frac{1}{2} \\theta^T C_{\\theta \\theta}^{-1} \\theta \\right] $\n",
    "\n",
    "This minimization problem can be solved using optimization techniques. The solution is a compromise between fitting the observed data and staying close to the prior distribution.\n",
    "\n",
    "In summary, both the unconstrained MMSE and the MAP estimators in this case turn out to be the same as the LMMSE estimator due to the Gaussian assumption for the prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1c6c9-c915-461b-98f9-80cab57177c1",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(b)}$ ${\\color{Blue} \\text{ What is the error covariance matrix ?} }$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "{\\color{Blue}\n",
    "R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE}= E_{\\theta} E_{Y|\\theta} \\tilde{\\theta}_{LMMSE}\\tilde{\\theta}^T_{LMMSE}\n",
    "}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75eea5a-c663-4ba7-b2de-fe76b92750be",
   "metadata": {},
   "source": [
    "Let's simplify the expression step by step. Recall the expression for the error covariance matrix $R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE}$:\n",
    "\n",
    "$ R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} = E_{\\theta} E_{Y|\\theta} (\\tilde{\\theta}_{LMMSE} - \\theta)(\\tilde{\\theta}_{LMMSE} - \\theta)^T $\n",
    "\n",
    "Now, substitute the expression for $\\tilde{\\theta}_{LMMSE}$:\n",
    "\n",
    "$ \\begin{split} R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} & = E_{\\theta} E_{Y|\\theta} \\left[(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} Y - (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} \\theta\\right] \\\\\n",
    "& \\qquad \\times \\left[Y^T C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} - \\theta^T C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1}\\right] \\end{split}$\n",
    "\n",
    "\n",
    "Let's simplify the terms inside the expectation. First, let's deal with the terms involving $Y$:\n",
    "\n",
    "$\\begin{split} & E_{\\theta} E_{Y|\\theta} \\left[(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} Y\\right] \\times \\left[Y^T C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1}\\right] \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} E_{\\theta} E_{Y|\\theta} [Y Y^T] C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta} + H^T C_{VV} H)H^T C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta} + H^T C_{VV} H)C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta} + H^T C_{VV} H)(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\end{split}$\n",
    "\n",
    "Now, let's deal with the terms involving $\\theta$:\n",
    "\n",
    "$ \\begin{split} & E_{\\theta} E_{Y|\\theta} \\left[(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} \\theta\\right] \\times \\left[\\theta^T C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1}\\right] \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} E_{\\theta}[\\theta \\theta^T] C_{VV}^{-T} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} C_{\\theta\\theta} C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta} + H^T C_{VV} H)C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\end{split} $\n",
    "\n",
    "Now, combine these two results:\n",
    "\n",
    "$ \\begin{split} R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} & = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta} + H^T C_{VV} H)C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\\\\n",
    "& \\quad - (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} \\end{split} $\n",
    "\n",
    "Now, simplify further by factoring out $(C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1}$:\n",
    "\n",
    "$ R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV}^{-1} H H^T C_{VV} C_{VV}^{-1} H (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} - (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} $\n",
    "\n",
    "Finally:\n",
    "\n",
    "$ R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} = (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} H^T C_{VV} C_{VV}^{-1} H (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} - (C_{\\theta\\theta}^{-1} + H^T C_{VV}^{-1} H)^{-1} $\n",
    "\n",
    "This is the simplified expression for the error covariance matrix $R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE}$. The final form is dependent on the specific structure of the matrices $C_{\\theta\\theta}$, $C_{VV}$, and the design matrix $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641a558-4bf8-46a2-ad92-941e78dc1abc",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(c)}$ ${\\color{Blue} \\text{ The conditional bias of an estimator } \\hat{\\theta} \\text{ is } b_{\\hat{\\theta}}(\\theta) = E_{Y | \\theta} \\hat{\\theta}(Y) − \\theta. }$\n",
    "${\\color{Blue} \\text{ The BLUE estimator is the LMMSE estimator under the constraint of conditional unbiasedness. So } b_{BLUE}(\\theta) = 0 }$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087798b5-ea8a-4c8f-b18f-902daef0b01f",
   "metadata": {},
   "source": [
    "${\\color{Blue} \\text{ What is } \\hat{\\theta}_{BLUE} \\text{ in terms of the quantities appearing in the Bayesian linear model  considered here? } }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d58a0e-e06c-4019-809f-49bfd40066bb",
   "metadata": {},
   "source": [
    "In the Bayesian linear model considered here, the BLUE (Best Linear Unbiased Estimator) for the parameter vector $\\theta$ is given by:\n",
    "\n",
    "$ \\hat{\\theta}_{\\text{BLUE}} = (H^T C_{VV}^{-1} H + C_{\\theta\\theta}^{-1})^{-1} H^T C_{VV}^{-1} Y $\n",
    "\n",
    "Let's break down the terms:\n",
    "\n",
    "- $Y$: Observed data vector.\n",
    "- $H$: Design matrix.\n",
    "- $C_{VV}$: Covariance matrix of the observation noise $V$.\n",
    "- $C_{\\theta\\theta}$: Covariance matrix of the prior distribution for $\\theta$.\n",
    "\n",
    "So, in terms of the quantities appearing in the Bayesian linear model:\n",
    "\n",
    "1. $H^T C_{VV}^{-1} H$: This term reflects the information provided by the observed data and how well it explains the variations in $\\theta$. It is weighted by the inverse covariance of the observation noise.\n",
    "\n",
    "2. $C_{\\theta\\theta}^{-1}$: This term reflects the precision of the prior information about $\\theta$. It is the inverse of the covariance matrix of the prior distribution for $\\theta$.\n",
    "\n",
    "3. $H^T C_{VV}^{-1} Y$: This term combines the information from the observed data with the inverse covariance of the observation noise.\n",
    "\n",
    "4. The entire expression $(H^T C_{VV}^{-1} H + C_{\\theta\\theta}^{-1})^{-1}$: This is the inverse of the sum of the information from the observed data and the precision of the prior distribution. It represents the combined information for estimating $\\theta$ in a linear, unbiased, and efficient manner.\n",
    "\n",
    "So, the BLUE estimator $\\hat{\\theta}_{\\text{BLUE}}$ balances the information from the observed data and the prior distribution, providing an optimal linear estimator for $\\theta$ in terms of unbiasedness and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62356e16-763e-41c0-b556-ae4250a1b0a4",
   "metadata": {},
   "source": [
    "${\\color{Blue} \\text{ Is there another classical deterministic estimator that equals } \\hat{\\theta}_{BLUE} \\text{ in this case? } }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9308ca5-aa4f-4b5c-9b4d-e9d05772f837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0610def5-f45b-4bc2-8d9d-a478c24925ee",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(d)}$ ${\\color{Blue} \\text{ What is the error covariance matrix ? }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cfdd4b-7026-44d0-84bb-93aaee87dd8c",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\color{Blue}\n",
    "\\begin{equation} \n",
    "R_{\\tilde{\\theta}\\tilde{\\theta}}^{BLUE}= E_{\\theta} E_{Y|\\theta} \\tilde{\\theta}_{BLUE}\\tilde{\\theta}^T_{BLUE}\n",
    "\\end{equation}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891423c5-ac51-4a76-a53f-d229684afabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f197a3e7-2744-42e6-806b-df80ef055200",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(e)}$ ${\\color{Blue} \\text{ Show that } R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} \\leq R_{\\tilde{\\theta}\\tilde{\\theta}}^{BLUE} }$\n",
    "${\\color{Blue} \\text{ Note that this is true in spite of } \\hat{\\theta}_{LMMSE} \\text{  being (conditionally) biased and } \\hat{\\theta}_{BLUE} \\text{  being unbiased. }}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd0099-6d11-4fdf-a5ef-3b4cf98b1f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5cedd3-8fa7-4df9-98dd-bef224e29b88",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(f)} {\\color{Blue} \\text{  Returning to } \\hat{\\theta}_{LMMSE} \\text{ , what is the bias } b_{LMMSE}(\\theta) ? }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4f6c4-8c04-4b50-82a2-d375310dd676",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(g)} {\\color{Blue} \\text{  Show that }}$\n",
    "\n",
    "$$\n",
    "{\\color{Blue}\n",
    "\\begin{gather}\n",
    "R_{\\tilde{\\theta}\\tilde{\\theta}} = \\frac{E_{\\theta} b_{\\hat\\theta}(\\theta) b_{\\hat\\theta}^T(\\theta)}{\\widehat{(bias)^2}} + \\frac{E_{\\theta}E_{Y | \\theta} (\\hat{\\theta} - E_{Y|\\theta}\\hat{\\theta})(\\hat{\\theta} - E_{Y|\\theta}\\hat{\\theta})^T }{\\widehat{variance}}\n",
    "\\end{gather}\n",
    "}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95618664-3f62-4bac-a27e-d96f11bd525c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef33c8e-9a1d-4f60-92bf-606fbbb0b011",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(h)} {\\color{Blue} \\text{ Compute } E_\\theta \\, b_{LMMSE}(\\theta) \\, b_{LMMSE}^T (\\theta) .}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60073456-bf44-4e23-8f29-1e36f8b76ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9adc6a17-478a-4ed1-bedb-1b788cb054d4",
   "metadata": {},
   "source": [
    "#### ${\\color{Green}(i)} {\\color{Blue} \\text{ Compute } E_{\\theta} E_{Y|\\theta} (\\tilde{\\theta}_{LMMSE} - E_{Y|\\theta} \\tilde{\\theta}_{LMMSE} ) \\, (\\tilde{\\theta}_{LMMSE} - E_{Y|\\theta} \\tilde{\\theta}_{LMMSE})^T .}$\n",
    "$\n",
    "{\\color{Blue} \\text{ Note that the sum of the positive definite matrices in}} {\\color{Green}(h)} {\\color{Blue} \\text{ and } } {\\color{Green}(i)}  {\\color{Blue} \\text{ yields } R_{\\tilde{\\theta}\\tilde{\\theta}}^{LMMSE} \\text{ , for which }} {\\color{Green}(e)} {\\color{Blue} \\text{ holds. }}\n",
    "$\n",
    "$\n",
    "{\\color{Blue} \\text{ Hence, in spite of the the fact that LMMSE introduces a (conditional) bias, it allows to reduce the variance }}\n",
    "$\n",
    "$\n",
    "{\\color{Blue} \\text{ so much that the sum of variance and squared bias gets lower than the variance in the unbiased case. }}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d2bda-b5a8-4012-9188-6f6653399e57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85dae447-acc4-4caa-9cfc-b4a4fea8a559",
   "metadata": {},
   "source": [
    "# References\n",
    "- [ ] [Bayesian/ MMSE Estimation for MIMO/ OFDM Wireless Communications](https://www.youtube.com/playlist?list=PLvb0jK8jJn_Zv6tnuHyWdxhohB3NzhG6N)\n",
    "   - [ ] [Two Important Quantities](https://www.youtube.com/watch?v=3mwN7Z18iSk&list=PLvb0jK8jJn_Zv6tnuHyWdxhohB3NzhG6N&t=1057s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da984b-2023-4b48-a22a-87479d6de4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
