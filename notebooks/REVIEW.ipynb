{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4667d7-0526-4ad2-8a74-ae17b35c526a",
   "metadata": {},
   "source": [
    "## ${\\color{Blue} \\text{ Part I: Spectrum Estimation }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ef1b1-10fb-489e-8d73-f8976927e671",
   "metadata": {},
   "source": [
    "**Review**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc20580-9606-4a5f-84d4-80da65626cc0",
   "metadata": {},
   "source": [
    "Given N samples ${\\{y_0, y_1, . . . , y_{N−1}\\}}$, the periodogram is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df2495-2a74-41ac-95a9-eed064b62588",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{S}_{yy}(\\mathit{f}) = \\hat{S}_{PER}(\\mathit{f}) = \\frac{1}{N} \\left| \\sum_{n=0}^{N-1} w_{N,n} y_n e^{-j2\\pi fn}  \\right|^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f13d0-5f0c-43d2-b4ee-e0deeb16deeb",
   "metadata": {},
   "source": [
    "where $w_{N,n}$ is a windowing function of size $N$ (rectangular by default). The window is normalized in the sense that $\\frac{1}{N} \\sum_{n=0}^{N-1} w_{N,n}^2 = 1$. In practice, the Fourier Transform (FFT)is computed as the Discrete Fourier Transform (DFT), for which fast algorithms exist known as Fast Fourier Transform (FFT). For computation of the DFT/FFT, it is customary to consider the frequency interval $[0, 1]$ rather than $[−\\frac{1}{2}, \\frac{1}{2} ]$. The DFT evaluates the Fourier transform of a signal of length $N$ at $N$ equispaced frequencies $f_k = k/N , k = 0,1,...,N−1$. So we get\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{S}_{yy}(\\mathit{f}) = \\hat{S}_{PER}(\\mathit{f}) = \\frac{1}{N} \\left| \\sum_{n=0}^{N-1} w_{N,n} y_n e^{-j2\\pi fn}  \\right|^2 = \\frac{1}{N} \\left| \\sum_{n=0}^{N-1} w_{N,n} y_n e^{-j2\\pi \\frac{k}{N}n}  \\right|^2, k = 0,1,...,N−1 .\n",
    "\\end{equation}\n",
    "$$\n",
    "We can obtain a finer frequency spacing by padding the data with $N' - N$ zeros and then applying an $N′$-point DFT.  The effective data set becomes\n",
    "$$\n",
    "\\begin{equation}\n",
    "y'_n = \n",
    "\\begin{cases}\n",
    "&y_n &, n = 0,1, ..., N - 1 \\\\\n",
    "&0 &, n = N, N+1, ..., N' - 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "which has the same Fourier transform as the original data set. The frequency spacing of the DFT on the data set $y′$ will be $\\frac{1}{N'} < \\frac{1}{N}$ . This **zero** padding gives no extra resolution, but only a finer evaluation of the periodogram. The window is still of size $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841bdd1-eb77-4f96-98f9-1778a4ee2aeb",
   "metadata": {},
   "source": [
    "In the autoregressive (AR) modeling (parametric) approach, we take\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{S}_{AR}(\\mathit{f}) =  \\frac{\\sigma^2_{f,n}}{|A_n(f)|^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "for an AR model of order n. The prediction coefficients $A_n = [1 A_{n,1} · · · A_{n,n}]T$ and the prediction error variance are obtained from the Yule-Walker (or normal) equations\n",
    "$$\n",
    "R_{n+1}A_n = \n",
    " \\begin{bmatrix}\n",
    "  r_0 & r_1 & \\cdots & r_n \\\\\n",
    "  r_1 & \\cdots & \\cdots & \\vdots \\\\\n",
    "  \\vdots  & \\cdots  & \\ddots & r_1  \\\\\n",
    "  r_n & \\cdots & r_1 & r_0\n",
    " \\end{bmatrix} = \n",
    " \\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  A_{n,1} \\\\\n",
    "  \\vdots \\\\\n",
    "  A_{n,n} \n",
    " \\end{bmatrix} =\n",
    " \\begin{bmatrix}\n",
    "  \\sigma_{f,n}^2 \\\\\n",
    "  0 \\\\\n",
    "  \\vdots \\\\\n",
    "  0\n",
    " \\end{bmatrix}\n",
    "$$\n",
    "where the correlation sequence is estimated as.\n",
    "$$\n",
    "r_k = \\hat{r}_{yy}(k) = \\frac{1}{N} \\sum_{n=0}^{N-1-k} y_n+ky_n, k = 0, 1, \\cdots, n .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bebf8-9b9f-4a33-8add-04ed90f05c1a",
   "metadata": {},
   "source": [
    "The frequencies f in (4) are again evaluated at the same discrete set. The prediction filter can be computed in an order-recursive $\\Delta_{n+1}$ fashion via the $\\underline{Levinson \\; algorithm}$: \n",
    "$\n",
    "\\quad\n",
    "\\begin{cases} \n",
    "A_n \\\\\n",
    "\\sigma_{f,n}^2\n",
    "\\end{cases}\n",
    "$\n",
    "$\n",
    "\\implies\n",
    "\\begin{cases} \n",
    "A_{n+1} \\\\\n",
    "\\sigma_{f,n+1}^2\n",
    "\\end{cases}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f78e8-dcc2-4f18-9cbc-e6f1dd45dada",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{gather}\n",
    "\\Delta_{n+1}= [r_{n+1} \\cdots r_1] A_n\n",
    "\\\\\n",
    "K_{n+1} = -\\frac{\\Delta_{n+1}}{\\sigma_{f,n}^2} \\qquad\n",
    "\\\\\n",
    "\\qquad \\qquad\n",
    "A_{n+1} = \n",
    "\\begin{bmatrix}\n",
    "A_n \\\\\n",
    "0\n",
    "\\end{bmatrix} +\n",
    "K_{n+1}\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "J A_n\n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\sigma_{f,n+1}^2 = \\sigma_{f,n}^2 \\left( 1 - K_{n+1}^2 \\right)\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fdaf8-2661-41af-baa7-b2a39571f82c",
   "metadata": {},
   "source": [
    "Initialisation $A_0 = [1], \\sigma_{f,0}^2 = r_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ee21d-3354-4af7-abe7-adfbdef49cd2",
   "metadata": {},
   "source": [
    "## ${\\color{Blue} \\text{ Part II: Parameter Estimation }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9e45f-0793-4388-a881-f323eb655f53",
   "metadata": {},
   "source": [
    "### Background on ML Estimation of Sinusoid in Noise Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bc92f-bdd4-495b-b73b-2db206c2b609",
   "metadata": {},
   "source": [
    "For this second part, consider a single sinusoid in white Gaussian noise with variance $\\sigma^2$\n",
    "$$\n",
    "y_k =s_k +v_k = A_1 \\cos(2\\pi f_1 k + \\phi_1) + v_k \\; , \\; k = 0, \\cdots , n − 1 .\n",
    "$$\n",
    "The Maximum Likelihood estimates of the paramteres $\\sigma^2, A_1, \\phi_1$ and $f_1$ can be shown to be obtained as\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{f}_1 = \\operatorname*{arg\\,max}_f |\\mathcal{Y}(f)| \\qquad \\qquad \\qquad \\qquad\n",
    "\\\\\n",
    "\\hat{A}_1 = \\frac{2}{n} | \\mathcal{Y}(\\hat{f}_1) | \\qquad \\qquad \\qquad \\qquad \\qquad \n",
    "\\\\\n",
    "\\hat{\\phi}_1 = \\operatorname*{arg}_{n - 1} \\mathcal{Y}(\\hat{f}_1) \\qquad \\qquad \\qquad \\qquad \\qquad \n",
    "\\\\\n",
    "\\widehat{\\sigma^2} = \\frac{1}{n} \\sum_{k=0}^{n-1} (y_k − \\hat{A}_1 \\cos(2\\pi \\hat{f}_1 k + \\hat{\\phi}_1))^2\n",
    "\\end{split}\n",
    "$$\n",
    "where $Y(f)= \\sum_{k=0}^{n-1} y_k e^{−j 2 \\pi f k} $ and $ \\operatorname{arg} \\{ \\rho e^{j \\theta} \\} = \\theta$. In order to turn the optimization problem $k=0$ for $\\hat{f}_1$ into a practical algorithm, we shall use the DFT. First decide on an acceptable “bias” in the ability to resolve the maximum of $|\\mathcal{Y}(f)|$. Let’s call the frequency resolution $\\Delta f$ :\n",
    "$$ \\Delta f = \\frac{1}{m}, \\; m = \\frac{1}{\\Delta f} .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852936c8-8bef-4b38-b8f5-126b088c184c",
   "metadata": {},
   "source": [
    "In order to have a DFT with such a frequency resolution, we need to have a signal of length $m$. We assume $m > n$, the number of samples available. Hence zero pad y_k to obtain $y_0,y_1,...,y_{m−1}$ where in fact $y_n = y_{n+1} = y_{m−1} = 0$. Take the DFT of the zero padded sequence (in Matlab, y_0 is the first element of a signal vector, y_1 the second etc.)\n",
    "$$Y_l = \\sum_{k=0}^{m-1} y_k e^{j 2 \\pi \\frac{l}{m} k} = \\sum_{k=0}^{n-1} y_k e^{j 2 \\pi \\frac{l}{n} k} .$$\n",
    "Then the Maximum Likelihood estimates can be approximately obtained as\n",
    "$$\n",
    "\\begin{split}\n",
    "\\hat{l} = \\operatorname*{arg\\,max}_l |\\mathcal{Y}_l|, \\qquad \\hat{f}_1 = \\frac{\\hat{l}}{m}, \\qquad \\hat{A}_1 = \\frac{2}{n} | \\mathcal{Y}_\\hat{l} | \\qquad \\qquad \n",
    "\\\\\n",
    "\\hat{\\phi}_1 = \\operatorname*{arg} \\mathcal{Y}\\hat{l}, \\quad \n",
    "\\widehat{\\sigma^2} = \\frac{1}{n} \\sum_{k=0}^{n-1} (y_k − \\hat{A}_1 \\cos(2\\pi \\hat{f}_1 k + \\hat{\\phi}_1))^2\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bc407-49a4-4b91-9197-ef974b8f421a",
   "metadata": {},
   "source": [
    "The search for $f_1$ should be limited to the interval $[0, \\frac{1}{2} ]$ (the DFT will show a symmetrical peak at $1-\\hat{f}_1$ ). Note that zeropadding only allows us to get within $\\Delta f = \\frac{1}{m}$ of the maximum of $|\\mathcal{Y}(f)|$. It does not improve the estimation accuracy (variance) of the estimator $\\hat{f}_1$. The variance can only be reduced by increasing the number of samples $n$ (see Cramer-Rao bound)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85081b27-be06-4fa2-b454-52a72d6ea95f",
   "metadata": {},
   "source": [
    "The Cramer-Rao bounds for the estimation of the various parameters can be shown to be:\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "CRB_{\\widehat{\\sigma^2}} = \\frac{2 \\sigma^4}{n} \\qquad CRB_{\\hat{A}_1} = \\frac{2 \\sigma^2}{n} \\\\\n",
    "CRB_{\\widehat{\\phi_1}} = \\frac{8 \\sigma^2}{n A_1^2 } \\qquad CRB_{\\widehat{f_1}} = \\frac{6 \\sigma^2}{\\pi^2 n^3 A_1^2 }\n",
    "\\end{gather}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89003d29-f771-45a7-b543-d7e8c0f0c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
